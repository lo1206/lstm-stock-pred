{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from random import randint\n",
    "import numpy as np \n",
    "import datetime\n",
    "from datetime import date\n",
    "import random\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.layers import add\n",
    "\n",
    "import pyodbc \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define groups of variables\n",
    "categorical_vars=['industry','weekday','year','month','month_day']\n",
    "other_vars=['Open','High','Low','Close','Volume']\n",
    "\n",
    "seq_length=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get All Stock\n",
    "conn = pyodbc.connect(\"Driver={SQL Server};Server=.\\SQLEXPRESS;Database=Stock;Trusted_Connection=yes;\")\n",
    "df_stockcode = pd.read_sql(\"SELECT distinct a.StockCode as stock_code,b.IndustryClassification as industry \\\n",
    "                            FROM StockPrice a left join StockMaster b on (a.StockCode=b.StockCode) \\\n",
    "                            ORDER BY industry,stock_code\" ,conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_list=dict()\n",
    "\n",
    "categorical_list['year']=[2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,\n",
    "                          2011,2012,2013,2014,2015,2016,2017,2018,2019,2020]\n",
    "categorical_list['weekday']=[0,1,2,3,4,5,6]\n",
    "categorical_list['month']=[1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "categorical_list['month_day']=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,\n",
    "                               21,22,23,24,25,26,27,28,29,30,31]\n",
    "categorical_list['industry']=list(df_stockcode['industry'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Variables\n",
    "token_index=dict()\n",
    "reverse_token_index=dict()\n",
    "\n",
    "for c in categorical_vars:\n",
    "    labels,uniques =pd.factorize(categorical_list[c])\n",
    "    token_index[c]=dict([(text,i) for i,text in enumerate(uniques)])\n",
    "    reverse_token_index[c]=dict([(i,text) for i,text in enumerate(uniques)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df():\n",
    "    # Pick stock\n",
    "    stock=random.choice(df_stockcode.stock_code.unique())\n",
    "\n",
    "    conn = pyodbc.connect(\"Driver={SQL Server};Server=.\\SQLEXPRESS;Database=Stock;Trusted_Connection=yes;\")\n",
    "    df_price = pd.read_sql(\"SELECT a.[StockCode] as stock_code, b.IndustryClassification as industry, a.[Date], a.[Open] ,a.[High],a.[Low],a.[Close],a.[Volume] \\\n",
    "                            FROM StockPrice a left join StockMaster b on (a.StockCode=b.StockCode)  \\\n",
    "                            WHERE  a.[StockCode]='\"+ stock +\"' \\\n",
    "                            ORDER BY DATEFROMPARTS('20'+RIGHT(a.[Date],2),LEFT(a.[Date],2),SUBSTRING(a.[Date],4,2)) \", conn)\n",
    "    conn.close()\n",
    "\n",
    "    # Date Variables\n",
    "    df_price['weekday'] = df_price['Date'].apply(lambda dateString : datetime.datetime.strptime(dateString, '%m/%d/%y').weekday())\n",
    "    df_price['year'] = df_price['Date'].apply(lambda dateString : datetime.datetime.strptime(dateString,'%m/%d/%y').year)\n",
    "    df_price['month'] = df_price['Date'].apply(lambda dateString : datetime.datetime.strptime(dateString, '%m/%d/%y').month)\n",
    "    df_price['month_day'] = df_price['Date'].apply(lambda dateString : datetime.datetime.strptime(dateString, '%m/%d/%y').day)\n",
    "\n",
    "    # Get Percentage Increase\n",
    "    df_price['pct_inc']=(df_price['Close']/df_price['Close'].shift())*100\n",
    "\n",
    "    # Get Break points\n",
    "    breaks= list(df_price.index[(abs(df_price['pct_inc'])>150) | (abs(df_price['pct_inc'])<50) ])\n",
    "    breaks.append(0)\n",
    "    breaks.append(len(df_price))\n",
    "    breaks.sort()\n",
    "    r=random.randint(1,len(breaks)-1)\n",
    "\n",
    "    df_price=df_price[breaks[r-1]: breaks[r]]\n",
    "   \n",
    "        \n",
    "    return df_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_single(sample_type):\n",
    "    \n",
    "    num_of_sample=1000\n",
    "    # Initialize positive and negative sample vectors\n",
    "    P1=np.zeros((num_of_sample, seq_length))\n",
    "    y=np.zeros((num_of_sample))\n",
    "    \n",
    "    # Get A Random Stock Dataset\n",
    "    while True:\n",
    "        df=get_df()\n",
    "        if len(df)>10*seq_length:\n",
    "            break\n",
    "\n",
    "    n=0\n",
    "    while n<num_of_sample :\n",
    "        # Generate random samples\n",
    "        r=randint(0, len(df)-3*seq_length)    \n",
    "        \n",
    "        h1=df['Close'].values[r:r+seq_length]\n",
    "        h2=df['Close'].values[r+seq_length:r+2*seq_length]\n",
    "\n",
    "        # Rescale \n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        h1= min_max_scaler.fit_transform(h1.reshape(-1,1)) \n",
    "        h2= min_max_scaler.fit_transform(h2.reshape(-1,1)) \n",
    "        \n",
    "        h1=h1.reshape((seq_length))\n",
    "        h2=h2.reshape((seq_length))\n",
    "        #print (h2)\n",
    "        slope,_,_,_,_= linregress(h2,range(0,seq_length) )\n",
    "        \n",
    "        P1[n]=h1\n",
    "        y[n]=0\n",
    "        \n",
    "        if sample_type=='postive':\n",
    "            if slope>50:\n",
    "                y[n]=1\n",
    "                n=n+1\n",
    "        else:\n",
    "            n=n+1\n",
    "\n",
    "\n",
    "    return P1,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=10\n",
    "h2=df['Close'].values[r+seq_length:r+2*seq_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1,y=sample_single('postive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "h2= min_max_scaler.fit_transform(h2.reshape(-1,1)) \n",
    "\n",
    "h2=h2.reshape((seq_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3047619 , 0.34285714, 0.3047619 , ..., 0.86666667, 0.82857143,\n",
       "        1.        ],\n",
       "       [0.03225806, 0.        , 0.03225806, ..., 0.5483871 , 0.47580645,\n",
       "        0.58870968],\n",
       "       [0.84375   , 1.        , 0.71875   , ..., 0.125     , 0.125     ,\n",
       "        0.28125   ],\n",
       "       ...,\n",
       "       [0.47619048, 0.39047619, 0.34285714, ..., 0.96190476, 0.91428571,\n",
       "        0.96190476],\n",
       "       [0.32142857, 0.32142857, 0.32142857, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.34285714, 0.3047619 , 0.34285714, ..., 0.96190476, 0.86666667,\n",
       "        0.82857143]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.3047619 , 0.34285714, 0.3047619 , ..., 0.86666667, 0.82857143,\n",
       "        1.        ],\n",
       "       [0.03225806, 0.        , 0.03225806, ..., 0.5483871 , 0.47580645,\n",
       "        0.58870968],\n",
       "       [0.84375   , 1.        , 0.71875   , ..., 0.125     , 0.125     ,\n",
       "        0.28125   ],\n",
       "       ...,\n",
       "       [0.47619048, 0.39047619, 0.34285714, ..., 0.96190476, 0.91428571,\n",
       "        0.96190476],\n",
       "       [0.32142857, 0.32142857, 0.32142857, ..., 1.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.34285714, 0.3047619 , 0.34285714, ..., 0.96190476, 0.86666667,\n",
       "        0.82857143]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(num_of_sample):\n",
    "    \n",
    "    X1=np.zeros((0,seq_length))\n",
    "    y=np.zeros((0))\n",
    "    \n",
    "    # Initialize sample variables\n",
    "    for i in range(0,num_of_sample):\n",
    "        if i%5==0:\n",
    "            print(i)\n",
    "        \n",
    "        X1_temp,y_temp=sample_single('postive')\n",
    "        X1=np.concatenate((X1,X1_temp))\n",
    "        y=np.concatenate((y,y_temp))\n",
    "        \n",
    "        X1_temp,y_temp=sample_single('negative')\n",
    "        X1=np.concatenate((X1,X1_temp))\n",
    "        y=np.concatenate((y,y_temp))\n",
    "        \n",
    "    return X1.reshape(-1,seq_length,1),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=Input((seq_length,1))\n",
    "Y=Conv1D(filters=128, kernel_size=2,activation='relu')(x)\n",
    "Y=Conv1D(filters=256, kernel_size=2,activation='relu')(Y)\n",
    "Y=MaxPooling1D(pool_size=2)(Y)\n",
    "Y=Conv1D(filters=128, kernel_size=2,activation='relu')(Y)\n",
    "Y=Conv1D(filters=256, kernel_size=2,activation='relu')(Y)\n",
    "Y=MaxPooling1D(pool_size=2)(Y)\n",
    "Y=GlobalAveragePooling1D()(Y)\n",
    "Y=Dropout(0.5)(Y)\n",
    "\n",
    "model_cov = Model(inputs=[x], outputs=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 50, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 49, 128)           384       \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 48, 256)           65792     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 24, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 23, 128)           65664     \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 22, 256)           65792     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 11, 256)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_7 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 197,632\n",
      "Trainable params: 197,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 50, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 49, 128)           384       \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 48, 256)           65792     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 24, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 23, 128)           65664     \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 22, 256)           65792     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 11, 256)           0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_7 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 197,632\n",
      "Trainable params: 197,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_cov.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1=Input((seq_length,1))\n",
    "\n",
    "Y1=model_cov(input1)\n",
    "\n",
    "# concatenate the two vectors\n",
    "#merged_layers = concatenate([Y1, Y2])\n",
    "#merged_layers=Flatten()(merged_layers)\n",
    "\n",
    "# And add a logistic regression on top\n",
    "Y1 = Dense(256, activation='relu')(Y1)\n",
    "Y1 = Dense(128, activation='relu')(Y1)\n",
    "\n",
    "predictions = Dense(1, activation='sigmoid')(Y1)\n",
    "\n",
    "model = Model(inputs=[input1], outputs=predictions)\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 50, 1)             0         \n",
      "_________________________________________________________________\n",
      "model_13 (Model)             (None, 256)               197632    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 296,449\n",
      "Trainable params: 296,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 50, 1)             0         \n",
      "_________________________________________________________________\n",
      "model_13 (Model)             (None, 256)               197632    \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 296,449\n",
      "Trainable params: 296,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "X1,y=sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/1\n",
      " 8560/18000 [=============>................] - ETA: 58:47 - loss: 0.6549 - acc: 0.5988"
     ]
    }
   ],
   "source": [
    "model.fit([X1], y,epochs=1,batch_size=16,verbose=1, validation_split=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000.0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
